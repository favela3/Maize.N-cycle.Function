---
title: "MM2017: Plant Genotype/Phenotye structures the micorbial community and it's function"
author: "Alonso Favela"
date: "11/5/2019"
output: html_document
Note: This work is being done on an exteral harddrive.
---
setwd("/Volumes/AlonsoF - HD/Maize Microbiome 2017/Maize Micorbiome Analysis /WGCNA")
setwd("/Volumes/AlonsoF - HD - Kent Lab/Maize Microbiome 2017/Seqeunce Data (HD copy)/Maize Micorbiome Analysis /WGCNA")
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("/Volumes/AlonsoF - HD/Maize Microbiome 2017/Maize Micorbiome Analysis /WGCNA")

r <- getOption("repos")
r["CRAN"] <- "https://mirror.las.iastate.edu/CRAN/"
options(repos = r)
```

This is an R Markdown file with code to run WGCNA with OTU/microbiome data.

## *Load packages*

```{r}

library(rmarkdown)

library(BiocManager)

# # # install pre-requisites
#  install.packages(c("matrixStats", "Hmisc", "splines", "foreach",
#  "doParallel", "fastcluster", "dynamicTreeCut", "survival"))
#  source("http://bioconductor.org/biocLite.R")
#  biocLite(c("GO.db", "preprocessCore", "impute"))
#  install.packages("flashClust")
#  library(flashClust)
# # # 
# # # # install WGCNA
#  install.packages("BiocManager")
# BiocManager::install("WGCNA") 

#load packages
suppressMessages(library(WGCNA))
allowWGCNAThreads()
suppressMessages(library(cluster))
options(stringsAsFactors = FALSE)

library(dplyr)
library(vegan)
```


## *Load data*
setwd("/Volumes/AlonsoF - HD/Maize Microbiome 2017/Maize Micorbiome Analysis /WGCNA")

#Loading in the 2017 Feild Study Data
```{r}

OTULoad <- read.csv("MM2017_OTU_w-r.csv", header = TRUE, row = "Samples")
metadataLoad <- read.csv("MM2017_Meta-Full.csv", header = TRUE, row = "Sample")
taxonomyLoad <- read.csv("MM2017_Taxa.csv", header = TRUE, row = "OTU")


```

```{r}
#Reload factors

OTU<-OTULoad
metadata<-metadataLoad
taxonomy<-taxonomyLoad
# subset metadata to include only relevant information for nifH rhizosphere samples

rownames(OTU)
rownames(metadata)
samples <- rownames(OTU)
samples
env <- subset(metadata, Samples %in% samples)
rownames(env)


```

```{r}
#This bit of code froms the teosinte treatments from the module: It also seems to be the fasts way to alter the model quickly
#T1- 1:59
#T2- 50:142
#T3- 142:222
#Teo-222:29X
# OTU<-OTU[c(142:222),]
# env<-env[c(142:222),]


# OTU<-OTU[c(1:59),]
# env<-env[c(1:59),]

#need to add offset of 1 to every values to eliminate 0 values prior to log tranformation
OTU <- OTU + 1
#conform no 0 values
sum(which(OTU == 0))

#function to filter out OTUs with abundance < 0.01%
# *To do this I changed the percentage to 1%*
low.count.removal = function(
data,
percent=0.001
){
keep.otu = which(colSums(data)*100/(sum(colSums(data))) > percent)
data.filter = data[,keep.otu]
return(list(data.filter = data.filter, keep.otu = keep.otu))
}
result.filter = low.count.removal(OTU, percent=0.01)
data.filter = result.filter$data.filter


#how many OTUs are retained?
length(result.filter$keep.otu)
# [1] Filtered at .01% of total read count: 1453 OTUs : 10,000 reads needed 
# [1] Filtered at .001% of total read count: 16383 OTUs | This is the same as no-filter : 1000 reads needed 
# [1] Filtered at .009% of total read count: 1590 : 9000 reads needed
# I think I'm going to go with the 

#Trying it with 11/6/19 .001% filter

# TSS normalization (relative abundance?)
TSS.divide <- function(x){
x/sum(x)
}

OTU_TSS <- t(apply(data.filter, 1, TSS.divide))
# Too big to view (R slows down)
#View(nifH_TSS)

OTU_norm <- log2(OTU_TSS)
rownames(OTU_norm)

samples <- rownames(OTU_norm)
samples
env <- subset(metadata, Samples %in% samples)

#Need to make stuff into dummy variables
library(fastDummies)
Genotype<-dummy_cols(env$Genotype)
Genotype <- Genotype[,-1]

Type<-dummy_cols(env$Type)
Type<-Type[,-1]
 
env1<-env[, -c(1,6,7)]

env1<-cbind(env1,Genotype,Type)

env1[,3]<-log(env1[,3])

# env1 <- env[,-1]
# rownames(env1)

# check that rownames in nifH_norm match env_norm
rownames(env1)
rownames(OTU_norm)

rownames(OTU_norm) == rownames(env1)



```

## *Identify and remove outliers*

```{r}

#sample network based on euclidian distance
A <- adjacency(t(OTU_norm), type = "distance")

#whole network connectivity
k <- as.numeric(apply(A, 2, sum))

#standardized connectivity
Z.k = scale(k)

#designate samples as outliers if Z.k value is below threshold
thresholdZ.k <- -5
outlierColor <- ifelse(Z.k < thresholdZ.k, "red", "black")

#generate cluster tree
sampleTree <- hclust(as.dist(1-A), method = "average")

#all data must be numeric
# env$Type <- as.numeric(as.factor(env$Type))
# env$Type <- as.numeric(env$Type)
# 
# env %>% mutate_if(is.factor, as.numeric)

# # select only numeric data
#  env1 <- env %>%
#   select(X._moisture, C.N, elevation, latitude, longitude, M3Ca, M3Fe, M3K, M3P, moisture, NH4, NO3, OM, pH, total_C, total_N)
# env1
# env1<-env[,-1]
# env1<-env1[,-c(1:6)]

envColors = data.frame(numbers2colors(env1, signed = FALSE))
dimnames(envColors)[[2]] = paste(names(env1), "C", sep = "")
datColors <- data.frame(outlierC = outlierColor, envColors)
#plot the samples dendrogram and the colors underneath
plotDendroAndColors(sampleTree, groupLabels = names(datColors),
colors = datColors)
```

## *Soft thresholding*
 
```{r}
# Choose a set of soft thresholding powers
powers = c(1:20)

# choose power based on SFT criterion (for unsigned network)
sft <- pickSoftThreshold(OTU_norm, powerVector = powers)

sft$powerEstimate

# Plot the results: NOTE I was unable to get get the exact code from the tutorial working if I ran them par(mfrow = c(1, 2))
# SFT index as a function of different powers

par(mfrow = c(1,2))

plot(sft$fitIndices[, 1], -sign(sft$fitIndices[, 3]) * sft$fitIndices[, 2],
xlab = "soft threshold power",
ylab = "SFT, signed R^2",
type = "n",
main = paste("Scale Independence")
)
text(sft$fitIndices[, 1], -sign(sft$fitIndices[, 3]) * sft$fitIndices[, 2], labels = powers, col = abline(h = 0.9, col = "red"))

     
# Mean connectivity as a function of different powers
plot(sft$fitIndices[, 1], sft$fitIndices[, 5],
xlab = "Soft Threshold (power)",
ylab = "Mean Connectivity",
type = "n",
main = paste("Mean Connectivity")
)
text(sft$fitIndices[, 1], sft$fitIndices[, 5], labels = powers, col = "red")
```

beta = 5

## *Module detection via dynamic tree cutting*

You can also the minModuleSize (minimum number of OTUs permitted per module).
Default = 30, but I increased to 50 to reduce the number of modules.
#After changing the maxblock size to 6000 it was able to manage the new size
# *The blocksize tells your community how much memory it can use!!! 1GB is about 1000 blocks. For a 8GB system I would limit it aroud 7000 blocks *
```{r}

mergingThresh = 0.20

net = blockwiseModules(OTU_norm, corType = "pearson",
maxBlockSize = 1000,
networkType = "unsigned",
power = 3,
minModuleSize =10,
mergeCutHeight = mergingThresh,
numericLabels = TRUE,
saveTOMs = TRUE,
pamRespectsDendro = FALSE,
saveTOMFileBase = "OTU_MM2017")
moduleLabelsAutomatic = net$colors

# Convert labels to colors for plotting
moduleColorsAutomatic = labels2colors(moduleLabelsAutomatic)

# A data frame with module eigengenes can be obtained as follows
MEsAutomatic = net$MEs
blocknumber = 1
datColors = data.frame(moduleColorsAutomatic)[net$blockGenes[[blocknumber]],]

# Plot the dendrogram and the module colors underneath
plotDendroAndColors(net$dendrograms[[blocknumber]],
colors = datColors,
groupLabels = c("Modules"),
dendroLabels = FALSE,
hang = 0.03, addGuide = TRUE,
guideHang = 0.05)


```

## *Method from online cluster approch, uses dynamic clustering*
```{r}

##Below is a method that uses a different type of threshold for merging. Via dynamic tree cutting
#Where elle's method used a stringent threshold for clustering that was not dynamic 
#The dynamic clustering seems to find more modules and almost puts everying in a module, perhaps the threshold is too weak

####Code take from https://wikis.utexas.edu/display/bioiteam/Clustering+using+WGCNA
softPower=8
adjacency = adjacency(OTU_norm, power = softPower, type = "signed") #specify network type
head(adjacency)
 
# Construct Networks- USE A SUPERCOMPUTER IRL -----------------------------
#translate the adjacency into topological overlap matrix and calculate the corresponding dissimilarity:
TOM = TOMsimilarity(adjacency, TOMType="signed") # specify network type
dissTOM = 1-TOM
 
# Generate Modules --------------------------------------------------------
 library(flashClust)
 
# Generate a clustered gene tree
geneTree = flashClust(as.dist(dissTOM), method="average")
plot(geneTree, xlab="", sub="", main= "Gene Clustering on TOM-based dissimilarity", labels= FALSE, hang=0.04)
#This sets the minimum number of genes to cluster into a module
minModuleSize = 10
dynamicMods = cutreeDynamic(dendro= geneTree, distM= dissTOM, deepSplit=2, pamRespectsDendro= FALSE, minClusterSize = minModuleSize)
dynamicColors= labels2colors(dynamicMods)
MEList= moduleEigengenes(OTU_norm, colors= dynamicColors,softPower = softPower)
MEs= MEList$eigengenes
MEDiss= 1-cor(MEs)
METree= flashClust(as.dist(MEDiss), method= "average")
save(dynamicMods, MEList, MEs, MEDiss, METree, file= "Network_allSamples_signed_RLDfiltered.RData")
 


#plots tree showing how the eigengenes cluster together
#INCLUE THE NEXT LINE TO SAVE TO FILE
#pdf(file="clusterwithoutmodulecolors.pdf")
plot(METree, main= "Clustering of module eigengenes", xlab= "", sub= "")
#set a threhold for merging modules. In this example we are not merging so MEDissThres=0.0
MEDissThres = 0.0
merge = mergeCloseModules(OTU_norm, dynamicColors, cutHeight= MEDissThres, verbose =3)
mergedColors = merge$colors
mergedMEs = merge$newMEs
#INCLUE THE NEXT LINE TO SAVE TO FILE
#dev.off()



#plot dendrogram with module colors below it
#INCLUE THE NEXT LINE TO SAVE TO FILE
#pdf(file="cluster.pdf")
plotDendroAndColors(geneTree, cbind(dynamicColors, mergedColors), c("Dynamic Tree Cut", "Merged dynamic"), dendroLabels= FALSE, hang=0.03, addGuide= TRUE, guideHang=0.05)
moduleColors = mergedColors
colorOrder = c("grey", standardColors(50))
moduleLabels = match(moduleColors, colorOrder)-1
MEs = mergedMEs
#INCLUE THE NEXT LINE TO SAVE TO FILE
#dev.off()

```

## *Relating modules to environmental data*

```{r}
# Choose a module assignment
moduleColors = moduleColorsAutomatic

# Define numbers of genes and samples
nOTU = ncol(OTU_norm)
10
nSamples = nrow(OTU_norm)

# Recalculate MEs with color labels
MEs0 = moduleEigengenes(OTU_norm, moduleColors)$eigengenes
MEsOTU = orderMEs(MEs0)
modEnvCor = cor(MEsOTU, env1, use = "p")

## Warning in storage.mode(y) <- "double": NAs introduced by coercion
modEnvP = corPvalueStudent(modEnvCor, nSamples)

# Since we have a moderately large number of modules and traits, a suitable graphical representation will 

textMatrix = paste(signif(modEnvCor, 2), "\n(", signif(modEnvP, 1), ")", sep = "")
dim(textMatrix) = dim(modEnvCor)
par(mar = c(6, 8.5, 3, 3))

# Display the correlation values within a heatmap plot
labeledHeatmap(Matrix = modEnvCor,
xLabels = names(env1),
yLabels = names(MEsOTU),
ySymbols = names(MEsOTU),
colorLabels = FALSE,
colors = blueWhiteRed(50),
textMatrix = textMatrix,
setStdMargins = FALSE,
cex.text = 0.5, zlim = c(-1, 1),
main = paste("Module-environmental relationships"))

# calculate the module membership values (aka. module eigengene based connectivity kME):
datKME = signedKME(OTU_norm, MEsOTU)

signif(cor(datKME, use="p"), 2)
dissimME=(1-t(cor(datKME, method="p")))/2
hclustdatME=hclust(as.dist(dissimME), method="average" )
# Plot the eigengene dendrogram
par(mfrow=c(1,1))
plot(hclustdatME, main="Clustering tree based of the module eigengenes")


```

##*Online method for trait correlation to modules*
```{r}
#Correlate traits --------------------------------------------------------
 
 
#Define number of genes and samples
nGenes = ncol(OTU_norm)
nSamples = nrow(OTU_norm)
#Recalculate MEs with color labels
MEs0 = moduleEigengenes(OTU_norm, moduleColors)$eigengenes
MEs = orderMEs(MEs0)
moduleTraitCor = cor(MEs, env1, use= "p")
moduleTraitPvalue = corPvalueStudent(moduleTraitCor, nSamples)
 
 
#Print correlation heatmap between modules and traits
textMatrix= paste(signif(moduleTraitCor, 2), "\n(",
                        signif(moduleTraitPvalue, 1), ")", sep= "")
dim(textMatrix)= dim(moduleTraitCor)
par(mar= c(6, 8.5, 3, 3))
 
 
#display the corelation values with a heatmap plot
#INCLUE THE NEXT LINE TO SAVE TO FILE
#pdf(file="heatmap.pdf")
labeledHeatmap(Matrix= moduleTraitCor,
            xLabels= names(env1),
            yLabels= names(MEs),
            ySymbols= names(MEs),
            colorLabels= FALSE,
            colors= blueWhiteRed(50),
            textMatrix= textMatrix,
            setStdMargins= FALSE,
            cex.text= 0.5,
            zlim= c(-1,1),
            main= paste("Module-trait relationships"))
#INCLUE THE NEXT LINE TO SAVE TO FILE
#dev.off()

```


## *Exporting results*

```{r}

# Check taxa annotation file
dim(taxonomy)
# [1] 5069    7
# [1] 37596     8

# Match taxa IDs in the data set to those of the annotation file 
head(rownames(taxonomy))
# [1] "OTU_1" "OTU_2" "OTU_3" "OTU_4" "OTU_5" "OTU_6"
tail(rownames(taxonomy))
# [1] "OTU_5256" "OTU_5257" "OTU_5258" "OTU_5259" "OTU_5260" "OTU_5261"

OTU_norm1 <- as.data.frame(OTU_norm)
dim(OTU_norm)
head(names(OTU_norm1))
# [1] "OTU_1" "OTU_2" "OTU_3" "OTU_4" "OTU_5" "OTU_6"
tail(names(OTU_norm1))
# [1] "OTU_5117" "OTU_5130" "OTU_5135" "OTU_5138" "OTU_5172" "OTU_5175"

taxa_annot <- as.matrix(taxonomy)

microbes <- names(OTU_norm1) 

annotation <- row.names(taxa_annot)

OTU2annot <- match(microbes, annotation)


# data frame with module significances (cor with the traits) 
OTU_env <- data.frame(cor(OTU_norm1, env1, use = "p")) 

names(OTU_env) <- paste("cor", names(OTU_env), sep = ".")

datOutput <- data.frame(ProbeID = names(OTU_norm1), taxonomy[OTU2annot, ], 
                       moduleColors, datKME, OTU_env)

# save the results in a comma delimited file 
write.table(datOutput, "2017_Filter_Maize_WGCNA_results2.csv", row.names = F, sep = ",")

# also export table containing module-trait correlations with p-values

modEnvCor <- textMatrix
colnames(modEnvCor) <- names(env1)

modEnvCor_df <- data.frame(Module = names(MEsOTU), modEnvCor)

write.table(modEnvCor, "2017_Filter_Maize_WGCNA_env_cor2.csv", sep = ",")

#produce df with cor and p vals for mod-trait correlations
modEnvCor <- data.frame(Module = names(MEsOTU), modEnvCor)

modEnvCor_lab <- modEnvCor
colnames(modEnvCor_lab) <- paste("cor", colnames(modEnvCor), sep = "_")

modEnvP_lab <- modEnvP
colnames(modEnvP_lab) <- paste("p", colnames(modEnvP_lab), sep = "_")


mod_cor_p <- data.frame(Module = names(MEsOTU), modEnvCor_lab, modEnvP_lab)

write.table(mod_cor_p, "MM2017_Filter_Maize_WGCNA_mod_cor_p2.csv", sep = ",")

# select modules
modules <- unique(datColors)
# Select module probes
probes <- names(OTU_norm1)
inModule <- is.finite(match(moduleColors,modules))
modProbes <- probes[inModule]
match1 <- match(modProbes, taxa_annot)

modOTUs <- taxa_annot[match1]

TOM <- TOMsimilarityFromExpr(OTU_norm1, power=7)

modTOM <- TOM[inModule, inModule]

dimnames(modTOM) = list(modProbes, modProbes)

# Export the network into edge and node list files for Cytoscape

cyt <- exportNetworkToCytoscape(modTOM,
edgeFile=paste("CytoEdge", ".txt",sep=""),
nodeFile=paste("CytoNode", ".txt",sep=""),
weighted = TRUE,
threshold = 0.02,
nodeNames=modProbes,
altNodeNames = modOTUs,
nodeAttr = moduleColors[inModule]
)

##Here I'll put some code to figure out how to make the egiengen trees

```

This "great table" code makes a table with ONLY significant module-environmantal trail correlations, with p-values.

```{r greattable}

#first identify correlations with significant p-vals
#obtain locations of cells where p<0.05

sig_env <- modEnvP < 0.005

#trait and module names as vectors
envtraits <- c(colnames(sig_env))
list(envtraits)
modules <-c (rownames(sig_env))

#modules names repeat
modEnvCor = cor(MEsOTU, env1, use = "p")
modules.f <- rep(modules, ncol(modEnvCor))
modules.f

#values as matrix
cor.v <- as.vector(modEnvCor)
pval.v <- as.vector(modEnvP)
cor.m <- matrix(data=(cor.v),byrow=F)
pval.m <- matrix(data=(pval.v),byrow=F)
TF.v <- as.vector(sig_env)
TF.m <- matrix(data=(TF.v),byrow=F)

#labels as matrix
env.m <- matrix(data=rep(envtraits, each=nrow(modEnvCor)), byrow=F)
mod.m <- matrix(data=modules.f, byrow=F)

#make single matrix (good table)
goodtable <- cbind(mod.m, env.m, cor.m, pval.m, TF.m)
 
summary(goodtable)
# mod.m = 272
# env.m = 272
# cor.m = 289 (remove first column, which contains module names) then = 272
# pval.m = 272
# TF.m = 272

#Name columns
goodtable.cnames <- c("module","trait","cor","pval","sig")
colnames(goodtable) <- goodtable.cnames
goodtable <- as.data.frame(goodtable)

#Remove sig=False rows
greattable <- filter(goodtable, sig == "TRUE")
 
greattable <- greattable[order(greattable$module), ]
greattable

#export
write.table(greattable, "MM2017_Filter_Maize_greattable2.csv", row.names = F, sep = ",")

#There is a shit ton of modules at the unfiltered level. is it tooooo much info

```

*Correcting for unwanted varaition in multivarate datasets*

```{r}
#https://peterlangfelder.com/2018/12/02/removal-of-unwanted-variation-based-on-a-subset-of-samples/
        
#Here is the Test code to figure out how to remove confounding effects from the model

#Needed to sva
# #if (!requireNamespace("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# 
# BiocManager::install("sva")
library(dplyr)
library(mgcv)
library(sva)
library(WGCNA)
options(stringsAsFactors = FALSE);

#Setting a bunch of random values 
nGenes = 1000;
nSamples1 = 8;
nSamples2 = 12;
disEffect = 0.5;
batchEffect = 0.4;
set.seed(2);


# Simulate first data set, genes in columns
data1 = matrix(rnorm(nSamples1 * nGenes), nSamples1, nGenes)
annotation1 = data.frame(
      status = sample(c("Ctrl", "Disease1"), nSamples1, replace = TRUE));
# Add a global effect of disaese
dSamples1 = annotation1$status=="Disease1"
data1[ dSamples1, ] = data1[ dSamples1, ] + 
      disEffect * matrix(rnorm(nGenes), sum(dSamples1), nGenes, byrow = TRUE)
# Simulate second data set
data2 = matrix(rnorm(nSamples2 * nGenes), nSamples2, nGenes)
annotation2 = data.frame(
     status = sample(c("Ctrl", "Disease2"), nSamples2, replace = TRUE));
# Add a global effect of disaese
dSamples2 = annotation2$status=="Disease2";
data2[ dSamples2, ] = data2[ dSamples2, ] + 
      disEffect * matrix(rnorm(nGenes), sum(dSamples2), nGenes, byrow = TRUE)

# Add a batch effect to second data set: shift each gene by a random amount
data2 = data2 + batchEffect * matrix(rnorm(nGenes), nSamples2, nGenes, byrow = TRUE)

#This code above illustrates a very intersting poing abou the random variable additon. 

# Prepare a function to plot principal components since we will use it a few times
plotPCA = function(data, annotation, ...)
{
  svd1 = svd(data, nu = 2, nv = 0);
  status = annotation$status;
  ctrlSamples = status=="Ctrl"
  status[ctrlSamples] = paste0(status[ctrlSamples], annotation$batch[ctrlSamples])
  layout(matrix(c(1:2), 1, 2), widths = c(0.3, 1))
  par(mar = c(3.2, 0, 0, 0));
  plot(c(0, 1), type = "n", axes = FALSE, 
       xlab = "", ylab = "");
  legend("bottomright", legend = sort(unique(status)), 
         pch = 20 + c(1:length(unique(status))), 
         pt.bg = labels2colors(1:length(unique(status))), 
         pt.cex = 2)
  par(mar = c(3.2, 3.2, 2, 1))
  par(mgp = c(2, 0.7, 0))
  plot(svd1$u[, 1], svd1$u[, 2], 
       xlab = "PC1", ylab = "PC2", 
       pch = 20 + as.numeric(factor(status)), 
       cex = 2.5, bg = labels2colors(status), cex.main = 1.0, ...)

}
        
        

# Merge the two data sets
data = rbind(data1, data2)
# Include a batch variable in the combined sample annotation
annotation = data.frame(
    rbind(annotation1, annotation2), 
    batch = c(rep(1, nSamples1), rep(2, nSamples2)))
# Plot PCs of the merged data
plotPCA(data, annotation, 
    main = "Merged data before batch correction")


###Here is where we attempt to remove these random effects from the model 


# Correct for the batch effect using empiricalBayesLM from WGCNA

###Below is the code that I should really focus on understanding. Here the model removes the added batch effects
#Then recalculates it based on some control varaible 
data.eblm = empiricalBayesLM(
   data, 
   removedCovariates = annotation$batch, 
   fitToSamples = annotation$status=="Ctrl")$adjustedData;

# See how well the correction worked
plotPCA(data.eblm, annotation, 
        main = "Corrected by regression on control samples")
        


##Here they compare the correction to an OLS adjustment
#OLS should only be used for diagnositc purposes

data.lm = empiricalBayesLM(data, removedCovariates = annotation$batch, 
   fitToSamples = annotation$status=="Ctrl")$adjustedData.OLS;
# See how well the correction worked
plotPCA(data.lm, annotation, 
        main = "Unmoderated regression on control samples")




####Lets try to use this bayesian removal of noise on with my data

plotPCA2 = function(data, annotation, status, ...)
{
  svd1 = svd(data, nu = 2, nv = 0);
  status = annotation$status;
  ctrlSamples = status=="Inbred"
  status[ctrlSamples] = paste0(status[ctrlSamples], annotation$batch[ctrlSamples])
  layout(matrix(c(1:2), 1, 2), widths = c(0.3, 1))
  par(mar = c(3.2, 0, 0, 0));
  plot(c(0, 1), type = "n", axes = FALSE, 
       xlab = "", ylab = "");
  legend("bottomright", legend = sort(unique(status)), 
         pch = 20 + c(1:length(unique(status))), 
         pt.bg = labels2colors(1:length(unique(status))), 
         pt.cex = 2)
  par(mar = c(3.2, 3.2, 2, 1))
  par(mgp = c(2, 0.7, 0))
  plot(svd1$u[, 1], svd1$u[, 2], 
       xlab = "PC1", ylab = "PC2", 
       pch = 20 + as.numeric(factor(status)), 
       cex = 2.5, bg = labels2colors(status), cex.main = 1.0, ...)

}

#Lets try a different thing
###This code below does not correct of the batch effects. The reason is because it doesnt work is because the model is not aware of the other treament
data.ComBat.naive = t(ComBat(t(data), batch = annotation$batch))
plotPCA(data.ComBat.naive, annotation, 
        main = "Naive application of ComBat")


##THis should correct for the batch effects
#Hhere we can see that comBat has the batch infromation, and the treatment of interact
data.ComBat = t(ComBat(t(data), batch = annotation$batch, 
                       mod = model.matrix(~status, data = annotation)))
plotPCA(data.ComBat, annotation, 
        main = "Correct application of ComBat")


##
data.OTU.ComBat = t(ComBat(t(OTU), batch = env$Rep, 
                       mod = model.matrix(~Genotype, data = env)))

````



